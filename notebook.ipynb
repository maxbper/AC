{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "datasets_dir = os.path.join(current_dir, 'datasets')\n",
    "awards_players_path = os.path.join(datasets_dir, 'awards_players.csv')\n",
    "coaches_path = os.path.join(datasets_dir, 'coaches.csv')\n",
    "players_teams_path = os.path.join(datasets_dir, 'players_teams.csv')\n",
    "players_path = os.path.join(datasets_dir, 'players.csv')\n",
    "series_post_path = os.path.join(datasets_dir, 'series_post.csv')\n",
    "team_post_path = os.path.join(datasets_dir, 'teams_post.csv')\n",
    "teams_path = os.path.join(datasets_dir, 'teams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset from the CSV file\n",
    "def read_dataset(path):\n",
    "    file = pd.read_csv(path)\n",
    "    return file\n",
    "\n",
    "# Calculate the mean for each column\n",
    "def mean_for_each_column(dataset):\n",
    "    print(\"..........Mean for each column..........\")\n",
    "    print(str(dataset.mean(numeric_only=True))+\"\\n\")\n",
    "\n",
    "# Calculate the median for each column\n",
    "def median_for_each_column(dataset):\n",
    "    print(\"..........Median for each column..........\")\n",
    "    print(str(dataset.median(numeric_only=True))+\"\\n\")\n",
    "\n",
    "# Calculate the mode for each column\n",
    "def mode_for_each_column(dataset):\n",
    "    print(\"..........Mode for each column..........\")\n",
    "    print(str(dataset.mode().iloc[0]) + \"\\n\")\n",
    "\n",
    "# Calculate the % of missing values for each column\n",
    "def missing_value_percentage_for_each_column(dataset):\n",
    "    total = dataset.shape[0]  # Number of lines\n",
    "    missing_values = dataset.isnull().sum()  # Sum of the missing values in each column\n",
    "    percentage = (missing_values / total) * 100  # Calculate the percentage of missing values in each column\n",
    "    print(\"..........% of missing values..........\")\n",
    "    print(percentage)\n",
    "\n",
    "# Box-plot for each column\n",
    "def box_plot_for_each_column(dataset):\n",
    "    numeric_columns = dataset.select_dtypes(include='number')\n",
    "    if numeric_columns.empty:\n",
    "        print(\"No numeric columns found in the dataset.\")\n",
    "    else:\n",
    "        numeric_columns.boxplot(figsize=(10, 6))\n",
    "        plt.title(\"Boxplot for all numeric columns\")\n",
    "        plt.xticks(rotation=45)  # Rotation in x, if necessary\n",
    "        plt.show()\n",
    "\n",
    "# Bar-chart for each column\n",
    "def bar_chart_for_each_column(dataset):\n",
    "    non_numeric_columns = dataset.select_dtypes(exclude='number')\n",
    "    if non_numeric_columns.empty:\n",
    "        print(\"Any non-numeric columns found in the dataset.\")\n",
    "    else:\n",
    "        for column in non_numeric_columns.columns:\n",
    "            value_counts = non_numeric_columns[column].value_counts()\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            value_counts.plot(kind='bar')\n",
    "            plt.title(f\"Bar chart for '{column}'\")\n",
    "            plt.xlabel(column)\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "            plt.show()\n",
    "\n",
    "# Pie-chart for each column\n",
    "def pie_chart_for_each_column(dataset):\n",
    "    non_numeric_columns = dataset.select_dtypes(exclude='number')\n",
    "    \n",
    "    if non_numeric_columns.empty:\n",
    "        print(\"Any non-numeric columns found in the dataset.\")\n",
    "    else:\n",
    "        for column in non_numeric_columns.columns:\n",
    "            # Count elements from different categories\n",
    "            category_counts = dataset[column].value_counts()\n",
    "            \n",
    "            # Pie-chart\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            category_counts.plot.pie(autopct='%1.1f%%', startangle=140)\n",
    "            plt.title(f'Distribution of {column}')\n",
    "            plt.ylabel('')  # Remove o rótulo do eixo Y\n",
    "            plt.show()\n",
    "\n",
    "#Pearson-correlation\n",
    "def pearson_correlation(dataset):\n",
    "    numeric_columns = dataset.select_dtypes(include='number')\n",
    "    \n",
    "    if numeric_columns.empty:\n",
    "        print(\"Nenhuma coluna numérica encontrada no dataset.\")\n",
    "    else:\n",
    "        # Correlation matrix\n",
    "        correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "        # View\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        plt.title('Pearson-correlation')\n",
    "        plt.show()\n",
    "\n",
    "#normalizar os valores entre o valor minimo e maximo\n",
    "def normalize_min_max(dataset):\n",
    "    # Seleciona as colunas numéricas\n",
    "    numeric_columns = dataset.select_dtypes(include='number')\n",
    "    \n",
    "    # Verifica se existem colunas numéricas\n",
    "    if numeric_columns.empty:\n",
    "        print(\"Nenhuma coluna numérica encontrada no dataset.\")\n",
    "        return dataset  # Retorna o dataset sem modificações se não houver colunas numéricas\n",
    "    \n",
    "    # Aplica a normalização Min-Max nas colunas numéricas\n",
    "    dataset[numeric_columns.columns] = (numeric_columns - numeric_columns.min()) / (numeric_columns.max() - numeric_columns.min())\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "#normalizar com base em média 0 e desvio padrão 1\n",
    "def normalize_mean_std(dataset):\n",
    "    # Seleciona as colunas numéricas\n",
    "    numeric_columns = dataset.select_dtypes(include='number')\n",
    "    \n",
    "    # Verifica se existem colunas numéricas\n",
    "    if numeric_columns.empty:\n",
    "        print(\"Nenhuma coluna numérica encontrada no dataset.\")\n",
    "        return dataset  # Retorna o dataset sem modificações se não houver colunas numéricas\n",
    "    \n",
    "    # Aplica a normalização Min-Max nas colunas numéricas\n",
    "    dataset[numeric_columns.columns] = (numeric_columns - numeric_columns.mean()) / numeric_columns.std()\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Guardar o dataset modificado numa nova pasta\n",
    "def save_cleaned_dataset(dataset, original_filename, new_folder_name='datasetsTratados'):\n",
    "    # Criar a nova pasta, se não existir\n",
    "    if not os.path.exists(new_folder_name):\n",
    "        os.makedirs(new_folder_name)\n",
    "    \n",
    "    # Definir o novo caminho de destino para o dataset\n",
    "    base_filename = os.path.basename(original_filename)\n",
    "    new_file_path = os.path.join(new_folder_name, base_filename)\n",
    "    \n",
    "    # Guardar o novo dataset\n",
    "    dataset.to_csv(new_file_path, index=False)\n",
    "    print(f\"Dataset guardado em: {new_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    awards_players_file = read_dataset(awards_players_path)\n",
    "    coaches_file = read_dataset(coaches_path)\n",
    "    players_teams_file = read_dataset(players_teams_path)\n",
    "    players_file = read_dataset(players_path)\n",
    "    series_post_file = read_dataset(series_post_path)\n",
    "    team_post_file = read_dataset(team_post_path)\n",
    "    teams_file = read_dataset(teams_path)\n",
    "    print(\"..........Dataset..........\")\n",
    "    print(awards_players_file)\n",
    "    print(coaches_file)\n",
    "    print(players_teams_file)\n",
    "    print(players_file)\n",
    "    print(series_post_file)\n",
    "    print(team_post_file)\n",
    "    print(teams_file) \n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_players_file = awards_players_file.drop(awards_players_file.columns[3], axis=1)\n",
    "coaches_file = coaches_file.drop(coaches_file.columns[3], axis=1)\n",
    "players_teams_file = players_teams_file.drop(players_teams_file.columns[4], axis=1)\n",
    "players_file = players_file[players_file['pos'].notna() & (players_file['pos'] != '')]\n",
    "players_file = players_file[~((players_file['height'] < 50))]\n",
    "players_file = players_file.drop(players_file.columns[[2,3,9]], axis=1)\n",
    "series_post_file = series_post_file.drop(series_post_file.columns[[4,6]], axis=1)\n",
    "team_post_file = team_post_file.drop(team_post_file.columns[2], axis=1)\n",
    "teams_file = teams_file.drop(teams_file.columns[[1,5]], axis=1)\n",
    "\n",
    "print(awards_players_file)\n",
    "print(coaches_file)\n",
    "print(players_teams_file)\n",
    "print(players_file)\n",
    "print(series_post_file)\n",
    "print(team_post_file)\n",
    "print(teams_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o dataset\n",
    "try:\n",
    "    mean_for_each_column(awards_players_file)\n",
    "    median_for_each_column(awards_players_file)\n",
    "    mode_for_each_column(awards_players_file)\n",
    "    missing_value_percentage_for_each_column(awards_players_file)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ler o dataset\n",
    "try:\n",
    "    # Criar box-plot e gráfico de barras\n",
    "    box_plot_for_each_column(awards_players_file)\n",
    "    bar_chart_for_each_column(awards_players_file)\n",
    "    pie_chart_for_each_column(awards_players_file)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Correlations\n",
    "    pearson_correlation(awards_players_file)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    print(\"..........Normalizacao com base min-max..........\")\n",
    "    print(normalize_min_max(awards_players_file))\n",
    "    print(\"..........Normalizacao com base moda e desvio padrao..........\")\n",
    "    print(normalize_mean_std(awards_players_file))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Função para ler dataset como dicionários\n",
    "def read_dataset(filepath):\n",
    "    with open(filepath, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        return list(reader)\n",
    "\n",
    "# Função para juntar datasets\n",
    "def join_datasets(teams_file, coaches_file):\n",
    "    combined_dataset = []\n",
    "\n",
    "    # Iterar pelas linhas do teams_file\n",
    "    for team_row in teams_file:\n",
    "        # Certificar-se de que team_row é um dicionário\n",
    "        if not isinstance(team_row, dict):\n",
    "            print(f\"Erro: Esperado dicionário, mas obtido {type(team_row)}\")\n",
    "            continue\n",
    "\n",
    "        # Procurar uma linha correspondente no coaches_file onde year e tmID coincidem\n",
    "        matching_coach_row = next(\n",
    "            (coach_row for coach_row in coaches_file \n",
    "             if coach_row['year'] == team_row['year'] and coach_row['tmID'] == team_row['tmID']), \n",
    "            None\n",
    "        )\n",
    "\n",
    "        # Se encontrar uma correspondência, juntar as duas linhas\n",
    "        if matching_coach_row:\n",
    "            # Caso tenha chaves duplicadas, renomear as chaves do coaches_file (opcional)\n",
    "            renamed_coach_row = {f\"coach_{key}\": value for key, value in matching_coach_row.items()}\n",
    "            \n",
    "            combined_row = {**team_row, **renamed_coach_row}  # Combina os dicionários\n",
    "            combined_dataset.append(combined_row)\n",
    "        else:\n",
    "            # Se não encontrar, apenas adicionar a linha do teams_file\n",
    "            combined_dataset.append(team_row)\n",
    "    \n",
    "    return combined_dataset\n",
    "\n",
    "# Determinar diretorias dos ficheiros\n",
    "current_dir = os.getcwd()\n",
    "datasets_dir = os.path.join(current_dir, 'datasets')\n",
    "\n",
    "teams_path = os.path.join(datasets_dir, 'teams.csv')\n",
    "coaches_path = os.path.join(datasets_dir, 'coaches.csv')\n",
    "\n",
    "# Ler os datasets\n",
    "try:\n",
    "    teams_file = read_dataset(teams_path)\n",
    "    coaches_file = read_dataset(coaches_path)\n",
    "\n",
    "    # Verificar se a leitura resultou em dicionários\n",
    "    if not teams_file or not isinstance(teams_file[0], dict):\n",
    "        raise ValueError(\"O arquivo teams.csv não foi lido corretamente.\")\n",
    "    if not coaches_file or not isinstance(coaches_file[0], dict):\n",
    "        raise ValueError(\"O arquivo coaches.csv não foi lido corretamente.\")\n",
    "\n",
    "    # Juntar os datasets\n",
    "    combined_dataset = join_datasets(teams_file, coaches_file)\n",
    "\n",
    "    # Exibir ou salvar o resultado\n",
    "    for row in combined_dataset:\n",
    "        print(row)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
