{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df1 = pd.read_csv('datasets/players.csv')\n",
    "df2 = pd.read_csv('datasets/players_teams.csv')\n",
    "df3 = pd.read_csv('datasets/awards_players.csv')\n",
    "df4 = pd.read_csv('datasets/teams.csv')\n",
    "df5 = pd.read_csv('datasets/teams_post.csv')\n",
    "df6 = pd.read_csv('datasets/coaches.csv')\n",
    "df7 = pd.read_csv('datasets/series_post.csv')\n",
    "\n",
    "def corrige_vencedor(teams, series_post):\n",
    "    # Itera sobre cada rodada ('F', 'CF', 'FR') para ajustar cada fase dos playoffs\n",
    "    for round_type in ['FR', 'CF', 'F']:\n",
    "        # Filtra a série específica da rodada\n",
    "        series_round = series_post[series_post['round'] == round_type]\n",
    "        \n",
    "        # Atualiza cada série individualmente\n",
    "        for _, row in series_round.iterrows():\n",
    "            year = row['year']\n",
    "            winner_id = row['tmIDWinner']\n",
    "            loser_id = row['tmIDLoser']\n",
    "            \n",
    "            # Define as colunas que correspondem às rodadas\n",
    "            if round_type == 'FR':\n",
    "                round_column = 'firstRound'\n",
    "            elif round_type == 'CF':\n",
    "                round_column = 'semis'\n",
    "            elif round_type == 'F':\n",
    "                round_column = 'finals'\n",
    "            \n",
    "            # Marca o time vencedor como \"W\" na rodada correspondente\n",
    "            teams.loc[(teams['year'] == year) & (teams['tmID'] == winner_id), round_column] = 'W'\n",
    "            \n",
    "            # Marca o time perdedor como \"L\" na rodada correspondente\n",
    "            teams.loc[(teams['year'] == year) & (teams['tmID'] == loser_id), round_column] = 'L'\n",
    "    \n",
    "    return teams\n",
    "\n",
    "teams_file = corrige_vencedor(df4, df7)\n",
    "\n",
    "players_teams_file = df2.drop(columns=['lgID'])\n",
    "players_file = df1[df1['pos'].notna() & (df1['pos'] != '')]\n",
    "players_file = players_file.drop(columns=['firstseason', 'lastseason', 'deathDate', 'collegeOther'])\n",
    "players_file['college'] = players_file['college'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "merged_df = pd.merge(players_teams_file, players_file, left_on='playerID', right_on='bioID', how='left')\n",
    "merged_df = merged_df.drop(columns=['bioID'])\n",
    "awards_players_file = df3.drop(columns=['lgID'])\n",
    "teams_file = df4.drop(columns=['lgID', 'divID', 'tmORB','tmDRB','tmTRB','opptmORB','opptmDRB','opptmTRB','seeded'])\n",
    "teams_file['playoff'] = teams_file['playoff'].apply(lambda x: 1 if x=='Y' else 0)\n",
    "\n",
    "team_post_file = df5.drop(columns=['lgID'])\n",
    "series_post_file = df7.drop(columns=['lgIDWinner', 'lgIDLoser'])\n",
    "coaches_file = df6.drop(columns=['lgID'])\n",
    "\n",
    "\n",
    "awards_grouped = awards_players_file.groupby(['playerID', 'year'])['award'].apply(list).reset_index()\n",
    "awards_grouped['award'] = awards_grouped['award'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "merged_df = pd.merge(merged_df, awards_grouped, on=['playerID', 'year'], how='left')\n",
    "merged_df['award'] = merged_df['award'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "merged_df = pd.merge(merged_df, teams_file, on=['tmID','year'], how = 'left')\n",
    "\n",
    "merged_df = merged_df.drop(columns=['franchID', 'name'])\n",
    "\n",
    "merged_df = pd.merge(merged_df, team_post_file, on=['tmID','year'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_count_per_team_year = merged_df.groupby(['year', 'tmID'])['playerID'].nunique().reset_index()\n",
    "player_count_per_team_year.columns = ['Year', 'Team', 'PlayerCount']\n",
    "\n",
    "# print(player_count_per_team_year)\n",
    "\n",
    "# Calculate min, max, and average player count for each year\n",
    "summary_stats = player_count_per_team_year.groupby('Year')['PlayerCount'].agg(['min', 'max', 'mean']).reset_index()\n",
    "summary_stats.columns = ['Year', 'MinPlayerCount', 'MaxPlayerCount', 'AvgPlayerCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_coaches_file = df3.rename(columns={'playerID': 'coachID'})\n",
    "coach_awards = awards_coaches_file[awards_coaches_file['award'] == 'Coach of the Year']\n",
    "coach_awards_grouped = coach_awards.groupby(['coachID', 'year'])['award'].apply(list).reset_index()\n",
    "coaches_file = pd.merge(coaches_file, coach_awards_grouped, on=['coachID', 'year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_oRebounds_by_pos = merged_df.groupby('pos')['oRebounds'].mean().reset_index()\n",
    "avg_dRebounds_by_pos = merged_df.groupby('pos')['dRebounds'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(columns=['rebounds', 'PostRebounds'])\n",
    "merged_df = merged_df.rename(columns={'GP_x': 'GP_player', 'GP_y': 'GP_team'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = merged_df.groupby('year').agg({\n",
    "    'o_pts': 'sum',\n",
    "    'o_fga': 'sum',\n",
    "    'o_oreb': 'sum',\n",
    "    'o_to': 'sum',\n",
    "    'o_fta': 'sum',\n",
    "    'o_asts': 'sum',\n",
    "    'o_fgm' : 'sum',\n",
    "    'o_ftm': 'sum',\n",
    "    'o_dreb':'sum',\n",
    "}).reset_index()\n",
    "\n",
    "grouped['VOP'] = grouped['o_pts'] / (grouped['o_fga'] - grouped['o_oreb'] + grouped['o_to'] + 0.44 * grouped['o_fta'])\n",
    "grouped['factor'] = (2 / 3) - (0.5 * (grouped['o_asts'] / grouped['o_fgm'])) / (2 * (grouped['o_fgm'] / grouped['o_ftm']))\n",
    "grouped['DRB%'] = (grouped['o_dreb'] - grouped['o_oreb']) / grouped['o_dreb']\n",
    "\n",
    "uPER_df = merged_df.groupby(['playerID', 'year']).agg({\n",
    "    'minutes': 'sum',     \n",
    "    'threeMade': 'sum',   \n",
    "    'assists': 'sum',     \n",
    "    'fgMade': 'sum',      \n",
    "    'ftMade': 'sum',      \n",
    "    'turnovers': 'sum',   \n",
    "    'fgAttempted': 'sum', \n",
    "    'ftAttempted': 'sum', \n",
    "    'dRebounds': 'sum',   \n",
    "    'oRebounds': 'sum',   \n",
    "    'steals': 'sum',      \n",
    "    'blocks': 'sum',      \n",
    "    'PF': 'sum'           \n",
    "}).reset_index()\n",
    "\n",
    "uPER_df = uPER_df.merge(grouped[['year', 'VOP', 'factor', 'DRB%']], on='year')\n",
    "\n",
    "uPER_df['TRB'] = uPER_df['dRebounds'] + uPER_df['oRebounds']\n",
    "\n",
    "uPER_df['uPER'] = (1 / uPER_df['minutes']) * (\n",
    "    uPER_df['threeMade'] +\n",
    "    (2/3) * uPER_df['assists'] +\n",
    "    (2 - uPER_df['factor'] * (uPER_df['assists'] / uPER_df['fgMade'])) * uPER_df['fgMade'] +\n",
    "    (uPER_df['ftMade'] * 0.5 * (1 + (1 - (uPER_df['assists'] / uPER_df['fgMade'])) + (2/3) * (uPER_df['assists'] / uPER_df['fgMade']))) -\n",
    "    uPER_df['VOP'] * uPER_df['turnovers'] -\n",
    "    uPER_df['VOP'] * uPER_df['DRB%'] * (uPER_df['fgAttempted'] - uPER_df['fgMade']) -\n",
    "    uPER_df['VOP'] * 0.44 * (0.44 + (0.56 * uPER_df['DRB%'])) * (uPER_df['ftAttempted'] - uPER_df['ftMade']) +\n",
    "    uPER_df['VOP'] * (1 - uPER_df['DRB%']) * uPER_df['TRB'] +\n",
    "    uPER_df['VOP'] * uPER_df['DRB%'] * uPER_df['oRebounds'] +\n",
    "    uPER_df['VOP'] * uPER_df['steals'] +\n",
    "    uPER_df['VOP'] * uPER_df['DRB%'] * uPER_df['blocks'] -\n",
    "    uPER_df['PF'] * ((grouped['o_ftm'].mean() / grouped['o_pts'].mean()) - 0.44 * (grouped['o_fta'].mean() / grouped['o_pts'].mean()) * uPER_df['VOP'])\n",
    ")\n",
    "\n",
    "lg_uPER = uPER_df.groupby('year')['uPER'].mean().reset_index()\n",
    "lg_uPER.rename(columns={'uPER': 'lg_uPER'}, inplace=True)\n",
    "\n",
    "uPER_df = uPER_df.merge(lg_uPER, on='year')\n",
    "\n",
    "uPER_df['PER'] = uPER_df['uPER'] * (15 / uPER_df['lg_uPER'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_to_merge = uPER_df[['playerID', 'year', 'PER']]\n",
    "merged_df = merged_df.merge(per_to_merge, on=['playerID', 'year'], how='left')\n",
    "\n",
    "merged_df['TS%'] = (merged_df['points'] / (2 * (merged_df['fgAttempted'] + 0.44 * merged_df['ftAttempted'])))*100\n",
    "merged_df['eFG%'] = ((merged_df['fgMade'] + 0.5 * merged_df['threeMade']) / merged_df['fgAttempted'])*100\n",
    "merged_df['stocks'] = (merged_df['steals'] + merged_df['blocks'])\n",
    "merged_df['dar'] = ((merged_df['steals'] + merged_df['blocks'] + merged_df['oRebounds'] + merged_df['dRebounds'])/merged_df['minutes'])\n",
    "\n",
    "merged_df['PER'] = merged_df['PER'].fillna(0)\n",
    "merged_df['TS%'] = merged_df['TS%'].fillna(0)\n",
    "merged_df['eFG%'] = merged_df['eFG%'].fillna(0)\n",
    "merged_df['stocks'] = merged_df['stocks'].fillna(0)\n",
    "merged_df['dar'] = merged_df['dar'].fillna(0)\n",
    "\n",
    "#Equipas que não foram aos playoffs\n",
    "merged_df['W'] = merged_df['W'].fillna(0)\n",
    "merged_df['L'] = merged_df['L'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot_for_each_column(dataset):\n",
    "    numeric_columns = dataset.select_dtypes(include='number')\n",
    "    if numeric_columns.empty:\n",
    "        print(\"No numeric columns found in the dataset.\")\n",
    "    else:\n",
    "        numeric_columns.boxplot(figsize=(10, 6))\n",
    "        plt.title(\"Boxplot for all numeric columns\")\n",
    "        plt.xticks(rotation=45)  # Rotation in x, if necessary\n",
    "        plt.show()\n",
    "\n",
    "def pearson_correlation(dataset, size_x, size_y):\n",
    "    numeric_columns = dataset.select_dtypes(include='number')\n",
    "    \n",
    "    if numeric_columns.empty:\n",
    "        print(\"Nenhuma coluna numérica encontrada no dataset.\")\n",
    "    else:\n",
    "        # Correlation matrix\n",
    "        correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "        # View\n",
    "        plt.figure(figsize=(size_x, size_y))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        plt.title('Pearson-correlation')\n",
    "        plt.show()\n",
    "\n",
    "def bar_chart_for_each_column(dataset):\n",
    "    non_numeric_columns = dataset.select_dtypes(exclude='number')\n",
    "    if non_numeric_columns.empty:\n",
    "        print(\"Any non-numeric columns found in the dataset.\")\n",
    "    else:\n",
    "        for column in non_numeric_columns.columns:\n",
    "            value_counts = non_numeric_columns[column].value_counts()\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            value_counts.plot(kind='bar')\n",
    "            plt.title(f\"Bar chart for '{column}'\")\n",
    "            plt.xlabel(column)\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "            plt.show()\n",
    "\n",
    "# Pie-chart for each column\n",
    "def pie_chart_for_each_column(dataset):\n",
    "    non_numeric_columns = dataset.select_dtypes(exclude='number')\n",
    "    \n",
    "    if non_numeric_columns.empty:\n",
    "        print(\"Any non-numeric columns found in the dataset.\")\n",
    "    else:\n",
    "        for column in non_numeric_columns.columns:\n",
    "            # Count elements from different categories\n",
    "            category_counts = dataset[column].value_counts()\n",
    "            \n",
    "            # Pie-chart\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            category_counts.plot.pie(autopct='%1.1f%%', startangle=140)\n",
    "            plt.title(f'Distribution of {column}')\n",
    "            plt.ylabel('')  # Remove o rótulo do eixo Y\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "#box_plot_for_each_column(merged_df)\n",
    "#box_plot_for_each_column(coaches_file)\n",
    "#box_plot_for_each_column(series_post_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearson_correlation(merged_df, 100, 80)\n",
    "#pearson_correlation(coaches_file, 8, 6)\n",
    "#pearson_correlation(series_post_file, 8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar_chart_for_each_column(merged_df)\n",
    "#bar_chart_for_each_column(coaches_file)\n",
    "#bar_chart_for_each_column(series_post_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pie_chart_for_each_column(merged_df)\n",
    "#pie_chart_for_each_column(coaches_file)\n",
    "#pie_chart_for_each_column(series_post_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceGameResults(column):\n",
    "    return column.apply(lambda value: '100' if value == 'W' else '010' if value == 'L' else '001')\n",
    "\n",
    "# Aplicar a função para cada coluna específica\n",
    "merged_df['firstRound'] = replaceGameResults(merged_df['firstRound'])\n",
    "merged_df['semis'] = replaceGameResults(merged_df['semis'])\n",
    "merged_df['finals'] = replaceGameResults(merged_df['finals'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('cleanDatasets'):\n",
    "    os.makedirs('cleanDatasets')\n",
    "\n",
    "merged_df.to_csv('cleanDatasets/players_and_teams.csv', index=False)\n",
    "coaches_file.to_csv('cleanDatasets/coaches_and_awards.csv', index=False)\n",
    "series_post_file.to_csv('cleanDatasets/series_post.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df2 = merged_df.drop(columns=['minutes','points','threeMade','assists','fgMade','turnovers','fgAttempted','ftAttempted','oRebounds','steals','blocks','PF','o_ftm','o_pts','o_fta','o_pts','o_fga','o_oreb','o_to','o_asts','o_fgm','o_dreb'])\n",
    "merged_df2 = merged_df2.drop(columns=['GP_player','GS','ftMade','threeAttempted','GP_team'])\n",
    "merged_df2 = merged_df2.drop(columns=['o_3pm','o_3pa','o_reb','o_pf','o_stl','o_blk','d_fgm','d_fga','d_ftm','d_fta','d_3pm','d_3pa','d_oreb','d_dreb','d_reb','d_asts','d_pf','d_stl','d_to','d_blk','d_pts'])\n",
    "merged_df2 = merged_df2.drop(columns=['PostGP','PostGS','PostMinutes','PostPoints','PostoRebounds','PostdRebounds','PostAssists','PostSteals','PostBlocks','PostTurnovers','PostPF','PostfgAttempted','PostfgMade','PostftAttempted','PostftMade','PostthreeAttempted','PostthreeMade','PostDQ'])\n",
    "merged_df2 = merged_df2.drop(columns=['arena'])\n",
    "\n",
    "merged_df2['birthDate'] = pd.to_datetime(merged_df['birthDate'], errors='coerce').dt.year\n",
    "merged_df2 = merged_df2.rename(columns={'birthDate': 'birthYear'})\n",
    "\n",
    "if not os.path.exists('cleanDatasets'):\n",
    "    os.makedirs('cleanDatasets')\n",
    "\n",
    "merged_df2.to_csv('cleanDatasets/advancedstatistics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_stats_prevYear = merged_df2[['playerID','year','PER', 'eFG%', 'TS%','stocks','dRebounds','dar']].drop_duplicates().copy() #TODO Acrescentar aqui mais variaveis\n",
    "\n",
    "players_stats_prevYear['year'] = players_stats_prevYear['year'] + 1\n",
    "\n",
    "\n",
    "players_stats_prevYear = players_stats_prevYear.merge(\n",
    "    merged_df2[['playerID', 'year', 'tmID', 'playoff']], \n",
    "    on=['playerID', 'year'], \n",
    "    how='left')\n",
    "\n",
    "players_stats_prevYear.to_csv('cleanDatasets/players_stats_prevYear.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.............................Fazer a media por equipa dos valores mas pegando apenas nos 7 melhores jogadores...............\n",
    "\n",
    "# Ordenar os jogadores dentro de cada equipe e ano com base no PER (ou outra métrica)\n",
    "players_stats_prevYear_sorted = players_stats_prevYear.sort_values(by=['tmID', 'year', 'PER'], ascending=[True, True, False])\n",
    "\n",
    "# Selecionar os 7 melhores jogadores de cada equipe e ano\n",
    "top_7_players = players_stats_prevYear_sorted.groupby(['tmID', 'year']).head(5)\n",
    "\n",
    "# Agora, calcular a média de PER, TS%, e eFG% apenas para os 7 melhores jogadores\n",
    "team_year_stats = top_7_players.groupby(['tmID', 'year', 'playoff'])[['PER', 'TS%', 'eFG%','stocks','dRebounds','dar']].mean().reset_index() #TODO Acrescentar aqui mais variavies\n",
    "\n",
    "\n",
    "# Salva o novo dataset em um arquivo CSV\n",
    "team_year_stats.to_csv('cleanDatasets/team_year_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    tmID  year  playoff        PER       eFG%  stocks\n",
      "0    ATL     9      0.0  19.894077  50.207877    26.6\n",
      "1    ATL    10      1.0  21.751629  51.579845    49.6\n",
      "2    CHA     2      1.0  20.571617  47.843485    29.0\n",
      "3    CHA     3      1.0  19.356376  47.204217    36.4\n",
      "4    CHA     4      1.0  20.989740  46.980211    37.6\n",
      "..   ...   ...      ...        ...        ...     ...\n",
      "121  WAS     6      0.0  17.387332  46.823234    46.8\n",
      "122  WAS     7      1.0  20.574946  51.330317    39.4\n",
      "123  WAS     8      0.0  21.686321  55.716693    47.8\n",
      "124  WAS     9      0.0  21.568455  45.065012    47.0\n",
      "125  WAS    10      1.0  19.989199  51.201160    32.2\n",
      "\n",
      "[126 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Selecionar as colunas de interesse\n",
    "features = team_year_stats[['PER', 'TS%', 'eFG%','stocks','dRebounds']] #TODO Acrescentar aqui tambem\n",
    "\n",
    "# Normalizar os dados usando MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Aplicar o PCA\n",
    "pca = PCA(n_components=3) #TODO mudar aqui o numero de colunas a selecionar\n",
    "pca.fit(features_scaled)\n",
    "\n",
    "# Verificar as cargas (coeficientes) dos componentes principais\n",
    "components = pca.components_\n",
    "\n",
    "# Baseado nas cargas, você pode decidir as variáveis mais importantes\n",
    "# Vamos mostrar a importância de cada variável nas componentes principais\n",
    "\n",
    "# Calcular a soma das cargas absolutas para cada variável\n",
    "importance = pd.DataFrame(abs(components), columns=['PER', 'TS%', 'eFG%','stocks','dRebounds'], index=['PC1', 'PC2','PC3']) #TODO mudar aqui as variaveis\n",
    "#TODO meter tantos PC quanto variaves a selecionar\n",
    "importance_sum = importance.sum(axis=0)\n",
    "\n",
    "# Selecionar as duas variáveis mais importantes\n",
    "most_important_features = importance_sum.sort_values(ascending=False).head(3) #TODO mudar aqui o numero de variaveis\n",
    "\n",
    "# Exibir apenas os nomes das variáveis mais importantes\n",
    "important_variable_names = most_important_features.index.tolist()\n",
    "\n",
    "# Inicializar a lista de componentes a serem removidos\n",
    "components_to_drop = ['PER', 'TS%', 'eFG%','stocks','dRebounds','dar'] #TODO mudar aqui as variavies (TODOS OS ATRIBUTOS AQUI)\n",
    "\n",
    "# Remover as variáveis mais importantes da lista de componentes a serem removidos\n",
    "components_to_drop = [col for col in components_to_drop if col not in important_variable_names]\n",
    "\n",
    "team_year_stats=team_year_stats.drop(columns=components_to_drop)\n",
    "\n",
    "# Exibir o resultado\n",
    "print(team_year_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tmID  year  playoff       PER      eFG%    stocks\n",
      "0  ATL     9      0.0  0.424361  0.642733  0.182965\n",
      "1  ATL    10      1.0  0.569981  0.695814  0.545741\n",
      "2  CHA     2      1.0  0.477476  0.551256  0.220820\n",
      "3  CHA     3      1.0  0.382209  0.526523  0.337539\n",
      "4  CHA     4      1.0  0.510254  0.517857  0.356467\n"
     ]
    }
   ],
   "source": [
    "# Normalizar os dados \n",
    "\n",
    "# Selecionar apenas colunas numéricas\n",
    "# Lista de colunas a normalizar\n",
    "columns_to_normalize = ['PER', 'eFG%', 'stocks'] #TODO baseado nas colunas selecionadas do dataset de cima\n",
    "\n",
    "# Aplicar a normalização apenas nas colunas selecionadas\n",
    "team_year_stats[columns_to_normalize] = team_year_stats[columns_to_normalize].apply(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min())\n",
    ")\n",
    "\n",
    "# Verificar o resultado\n",
    "print(team_year_stats.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir o dataset para treino, validacao e teste \n",
    "\n",
    "dataset_treino = team_year_stats[(team_year_stats['year'] >= 7) & (team_year_stats['year'] <= 9)]\n",
    "dataset_teste = team_year_stats[team_year_stats['year'] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Features (X) e alvo (y)\n",
    "X_treino = dataset_treino[important_variable_names] #Antigamente 'PER', 'TS%', 'eFG%'\n",
    "y_treino = dataset_treino['playoff']\n",
    "\n",
    "X_teste = dataset_teste[important_variable_names]\n",
    "y_teste = dataset_teste['playoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) na validação: 0.17463076923076923\n",
      "R² score na validação: 0.2621850000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/3804687974.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>stocks</th>\n",
       "      <th>playoff_previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.494162</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631008</td>\n",
       "      <td>0.613080</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.427084</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IND</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478243</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.557230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MIN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.499098</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NYL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516902</td>\n",
       "      <td>0.679304</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SAC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488918</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.359621</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SEA</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto\n",
       "1    ATL    10      1.0  0.569981  0.695814  0.545741              0.85\n",
       "11   CHI    10      0.0  0.434645  0.494162  0.630915              0.73\n",
       "21   CON    10      0.0  0.631008  0.613080  0.315457              0.23\n",
       "30   DET    10      1.0  0.667559  0.427084  0.268139              0.71\n",
       "47   IND    10      1.0  0.478243  0.561043  0.659306              0.60\n",
       "56   LAS    10      1.0  0.791341  0.557230  1.000000              0.89\n",
       "67   MIN    10      0.0  0.684573  0.499098  0.772871              0.77\n",
       "76   NYL    10      0.0  0.516902  0.679304  0.362776              0.52\n",
       "87   PHO    10      1.0  0.717072  0.688872  0.476341              0.91\n",
       "98   SAC    10      0.0  0.488918  0.617841  0.359621              0.31\n",
       "105  SAS    10      1.0  0.381001  0.680233  0.511041              0.66\n",
       "114  SEA    10      1.0  0.391775  0.553947  0.394322              0.75\n",
       "125  WAS    10      1.0  0.431818  0.681163  0.271293              0.49"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar o modelo de regressão\n",
    "modelo = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Treinar com os dados de treino\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "print(\"Mean Squared Error (MSE) na validação:\", mse)\n",
    "print(\"R² score na validação:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "dataset_teste.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) no teste: 0.2991158585788189\n",
      "R² score no teste: -0.26376450249550953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/2857818035.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>stocks</th>\n",
       "      <th>playoff_previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>0.724031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.494162</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.817805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631008</td>\n",
       "      <td>0.613080</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.471213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.427084</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.446601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IND</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478243</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.854950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.557230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.348043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MIN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.499098</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>1.053017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NYL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516902</td>\n",
       "      <td>0.679304</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.490997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.678520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SAC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488918</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.359621</td>\n",
       "      <td>0.487723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.635609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SEA</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.512887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.358228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto\n",
       "1    ATL    10      1.0  0.569981  0.695814  0.545741          0.724031\n",
       "11   CHI    10      0.0  0.434645  0.494162  0.630915          0.817805\n",
       "21   CON    10      0.0  0.631008  0.613080  0.315457          0.471213\n",
       "30   DET    10      1.0  0.667559  0.427084  0.268139          0.446601\n",
       "47   IND    10      1.0  0.478243  0.561043  0.659306          0.854950\n",
       "56   LAS    10      1.0  0.791341  0.557230  1.000000          1.348043\n",
       "67   MIN    10      0.0  0.684573  0.499098  0.772871          1.053017\n",
       "76   NYL    10      0.0  0.516902  0.679304  0.362776          0.490997\n",
       "87   PHO    10      1.0  0.717072  0.688872  0.476341          0.678520\n",
       "98   SAC    10      0.0  0.488918  0.617841  0.359621          0.487723\n",
       "105  SAS    10      1.0  0.381001  0.680233  0.511041          0.635609\n",
       "114  SEA    10      1.0  0.391775  0.553947  0.394322          0.512887\n",
       "125  WAS    10      1.0  0.431818  0.681163  0.271293          0.358228"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar o modelo de regressão linear\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Mean Squared Error (MSE) no teste:\", mse)\n",
    "print(\"R² score no teste:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "dataset_teste.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) no teste: 0.24630559005341002\n",
      "R² score no teste: -0.04064111797565717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/11041507.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>stocks</th>\n",
       "      <th>playoff_previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>0.684309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.494162</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.682951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631008</td>\n",
       "      <td>0.613080</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.564085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.427084</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.531882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IND</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478243</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.714708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.557230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MIN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.499098</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.823488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NYL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516902</td>\n",
       "      <td>0.679304</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.567930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.680858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SAC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488918</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.359621</td>\n",
       "      <td>0.554495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.617660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SEA</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.545149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.496274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto\n",
       "1    ATL    10      1.0  0.569981  0.695814  0.545741          0.684309\n",
       "11   CHI    10      0.0  0.434645  0.494162  0.630915          0.682951\n",
       "21   CON    10      0.0  0.631008  0.613080  0.315457          0.564085\n",
       "30   DET    10      1.0  0.667559  0.427084  0.268139          0.531882\n",
       "47   IND    10      1.0  0.478243  0.561043  0.659306          0.714708\n",
       "56   LAS    10      1.0  0.791341  0.557230  1.000000          0.980892\n",
       "67   MIN    10      0.0  0.684573  0.499098  0.772871          0.823488\n",
       "76   NYL    10      0.0  0.516902  0.679304  0.362776          0.567930\n",
       "87   PHO    10      1.0  0.717072  0.688872  0.476341          0.680858\n",
       "98   SAC    10      0.0  0.488918  0.617841  0.359621          0.554495\n",
       "105  SAS    10      1.0  0.381001  0.680233  0.511041          0.617660\n",
       "114  SEA    10      1.0  0.391775  0.553947  0.394322          0.545149\n",
       "125  WAS    10      1.0  0.431818  0.681163  0.271293          0.496274"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#::::::::::::::::::::Este modelo é uma variante da regressão linear que usa regularização L2 para reduzir overfitting.::::::::::::::::\n",
    "\n",
    "# Inicializar o modelo de Ridge Regression\n",
    "modelo = Ridge(alpha=1.0)  # alpha controla o nível de regularização\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Mean Squared Error (MSE) no teste:\", mse)\n",
    "print(\"R² score no teste:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "dataset_teste.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) no teste: 0.23758751658811145\n",
      "R² score no teste: -0.00380725758477074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/613287734.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>stocks</th>\n",
       "      <th>playoff_previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.494162</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631008</td>\n",
       "      <td>0.613080</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.427084</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IND</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478243</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.557230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MIN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.499098</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NYL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516902</td>\n",
       "      <td>0.679304</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SAC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488918</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.359621</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SEA</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto\n",
       "1    ATL    10      1.0  0.569981  0.695814  0.545741          0.585366\n",
       "11   CHI    10      0.0  0.434645  0.494162  0.630915          0.585366\n",
       "21   CON    10      0.0  0.631008  0.613080  0.315457          0.585366\n",
       "30   DET    10      1.0  0.667559  0.427084  0.268139          0.585366\n",
       "47   IND    10      1.0  0.478243  0.561043  0.659306          0.585366\n",
       "56   LAS    10      1.0  0.791341  0.557230  1.000000          0.585366\n",
       "67   MIN    10      0.0  0.684573  0.499098  0.772871          0.585366\n",
       "76   NYL    10      0.0  0.516902  0.679304  0.362776          0.585366\n",
       "87   PHO    10      1.0  0.717072  0.688872  0.476341          0.585366\n",
       "98   SAC    10      0.0  0.488918  0.617841  0.359621          0.585366\n",
       "105  SAS    10      1.0  0.381001  0.680233  0.511041          0.585366\n",
       "114  SEA    10      1.0  0.391775  0.553947  0.394322          0.585366\n",
       "125  WAS    10      1.0  0.431818  0.681163  0.271293          0.585366"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar ao Ridge, mas utiliza regularização L1. Tende a eliminar variáveis menos importantes, útil para seleção de features.\n",
    "# Inicializar o modelo de Lasso Regression\n",
    "modelo = Lasso(alpha=0.1, random_state=42)  # alpha controla a força da regularização\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Mean Squared Error (MSE) no teste:\", mse)\n",
    "print(\"R² score no teste:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "dataset_teste.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) no teste: 0.23758751658811145\n",
      "R² score no teste: -0.00380725758477074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/260154350.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>stocks</th>\n",
       "      <th>playoff_previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.494162</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631008</td>\n",
       "      <td>0.613080</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.427084</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IND</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478243</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.557230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MIN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.499098</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NYL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516902</td>\n",
       "      <td>0.679304</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SAC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488918</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.359621</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SEA</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto\n",
       "1    ATL    10      1.0  0.569981  0.695814  0.545741          0.585366\n",
       "11   CHI    10      0.0  0.434645  0.494162  0.630915          0.585366\n",
       "21   CON    10      0.0  0.631008  0.613080  0.315457          0.585366\n",
       "30   DET    10      1.0  0.667559  0.427084  0.268139          0.585366\n",
       "47   IND    10      1.0  0.478243  0.561043  0.659306          0.585366\n",
       "56   LAS    10      1.0  0.791341  0.557230  1.000000          0.585366\n",
       "67   MIN    10      0.0  0.684573  0.499098  0.772871          0.585366\n",
       "76   NYL    10      0.0  0.516902  0.679304  0.362776          0.585366\n",
       "87   PHO    10      1.0  0.717072  0.688872  0.476341          0.585366\n",
       "98   SAC    10      0.0  0.488918  0.617841  0.359621          0.585366\n",
       "105  SAS    10      1.0  0.381001  0.680233  0.511041          0.585366\n",
       "114  SEA    10      1.0  0.391775  0.553947  0.394322          0.585366\n",
       "125  WAS    10      1.0  0.431818  0.681163  0.271293          0.585366"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combina as regularizações L1 (Lasso) e L2 (Ridge).\n",
    "# Inicializar o modelo de Elastic Net\n",
    "modelo = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "# `alpha` controla a força total da regularização.\n",
    "# `l1_ratio` controla a proporção de regularização L1 (Lasso) em relação à L2 (Ridge).\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Mean Squared Error (MSE) no teste:\", mse)\n",
    "print(\"R² score no teste:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "dataset_teste.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) no teste: 0.2631253217783924\n",
      "R² score no teste: -0.11170448451370762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/2522216952.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>stocks</th>\n",
       "      <th>playoff_previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>0.717456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.494162</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.764713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631008</td>\n",
       "      <td>0.613080</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.507723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.427084</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.471178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IND</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478243</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.800615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.557230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.088906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MIN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.499098</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.917727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NYL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516902</td>\n",
       "      <td>0.679304</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.519572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.675056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SAC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488918</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.359621</td>\n",
       "      <td>0.513501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.641248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SEA</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.537472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.411076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto\n",
       "1    ATL    10      1.0  0.569981  0.695814  0.545741          0.717456\n",
       "11   CHI    10      0.0  0.434645  0.494162  0.630915          0.764713\n",
       "21   CON    10      0.0  0.631008  0.613080  0.315457          0.507723\n",
       "30   DET    10      1.0  0.667559  0.427084  0.268139          0.471178\n",
       "47   IND    10      1.0  0.478243  0.561043  0.659306          0.800615\n",
       "56   LAS    10      1.0  0.791341  0.557230  1.000000          1.088906\n",
       "67   MIN    10      0.0  0.684573  0.499098  0.772871          0.917727\n",
       "76   NYL    10      0.0  0.516902  0.679304  0.362776          0.519572\n",
       "87   PHO    10      1.0  0.717072  0.688872  0.476341          0.675056\n",
       "98   SAC    10      0.0  0.488918  0.617841  0.359621          0.513501\n",
       "105  SAS    10      1.0  0.381001  0.680233  0.511041          0.641248\n",
       "114  SEA    10      1.0  0.391775  0.553947  0.394322          0.537472\n",
       "125  WAS    10      1.0  0.431818  0.681163  0.271293          0.411076"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar o modelo de MLP\n",
    "modelo = MLPRegressor(hidden_layer_sizes=(100, 50),  # Camadas ocultas com 100 e 50 neurônios\n",
    "                      activation='relu',            # Função de ativação\n",
    "                      solver='adam',                # Otimizador\n",
    "                      max_iter=500,                 # Número máximo de iterações\n",
    "                      random_state=42)\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Mean Squared Error (MSE) no teste:\", mse)\n",
    "print(\"R² score no teste:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "dataset_teste.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emamartins12/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6753 - val_loss: 0.7593\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.6425 - val_loss: 0.7203\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.6106 - val_loss: 0.6836\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.5798 - val_loss: 0.6489\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5504 - val_loss: 0.6151\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5223 - val_loss: 0.5818\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.4954 - val_loss: 0.5499\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.4699 - val_loss: 0.5203\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4457 - val_loss: 0.4918\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4230 - val_loss: 0.4646\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4014 - val_loss: 0.4387\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3808 - val_loss: 0.4139\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3615 - val_loss: 0.3905\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3432 - val_loss: 0.3695\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3259 - val_loss: 0.3506\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3101 - val_loss: 0.3330\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2961 - val_loss: 0.3170\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2835 - val_loss: 0.3022\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2724 - val_loss: 0.2884\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2624 - val_loss: 0.2756\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2537 - val_loss: 0.2638\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2461 - val_loss: 0.2534\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2396 - val_loss: 0.2445\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2341 - val_loss: 0.2368\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2296 - val_loss: 0.2303\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2259 - val_loss: 0.2244\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2230 - val_loss: 0.2193\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2209 - val_loss: 0.2151\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2194 - val_loss: 0.2118\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2184 - val_loss: 0.2091\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2179 - val_loss: 0.2071\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2179 - val_loss: 0.2058\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2181 - val_loss: 0.2048\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2185 - val_loss: 0.2043\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2189 - val_loss: 0.2038\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2194 - val_loss: 0.2035\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2199 - val_loss: 0.2032\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.2202 - val_loss: 0.2031\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2204 - val_loss: 0.2030\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2204 - val_loss: 0.2030\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2202 - val_loss: 0.2030\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2199 - val_loss: 0.2031\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2194 - val_loss: 0.2032\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2189 - val_loss: 0.2034\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2184 - val_loss: 0.2036\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2178 - val_loss: 0.2040\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2172 - val_loss: 0.2045\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2166 - val_loss: 0.2050\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2161 - val_loss: 0.2056\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2157 - val_loss: 0.2063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Mean Squared Error (MSE) no teste: 0.24003951575346605\n",
      "R² score no teste: -0.014166954058393744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/1782423946.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>stocks</th>\n",
       "      <th>playoff_previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>0.710978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.494162</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.688451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631008</td>\n",
       "      <td>0.613080</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.558874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.427084</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.479837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IND</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478243</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.728010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.557230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MIN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.499098</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.780201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NYL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516902</td>\n",
       "      <td>0.679304</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.597960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.675911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SAC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488918</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.359621</td>\n",
       "      <td>0.576237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.676908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SEA</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.571752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.542244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto\n",
       "1    ATL    10      1.0  0.569981  0.695814  0.545741          0.710978\n",
       "11   CHI    10      0.0  0.434645  0.494162  0.630915          0.688451\n",
       "21   CON    10      0.0  0.631008  0.613080  0.315457          0.558874\n",
       "30   DET    10      1.0  0.667559  0.427084  0.268139          0.479837\n",
       "47   IND    10      1.0  0.478243  0.561043  0.659306          0.728010\n",
       "56   LAS    10      1.0  0.791341  0.557230  1.000000          0.926178\n",
       "67   MIN    10      0.0  0.684573  0.499098  0.772871          0.780201\n",
       "76   NYL    10      0.0  0.516902  0.679304  0.362776          0.597960\n",
       "87   PHO    10      1.0  0.717072  0.688872  0.476341          0.675911\n",
       "98   SAC    10      0.0  0.488918  0.617841  0.359621          0.576237\n",
       "105  SAS    10      1.0  0.381001  0.680233  0.511041          0.676908\n",
       "114  SEA    10      1.0  0.391775  0.553947  0.394322          0.571752\n",
       "125  WAS    10      1.0  0.431818  0.681163  0.271293          0.542244"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inicializar o modelo sequencial\n",
    "modelo = Sequential()\n",
    "\n",
    "# Adicionar camadas\n",
    "modelo.add(Dense(64, activation='relu', input_shape=(X_treino.shape[1],)))  # Primeira camada oculta\n",
    "modelo.add(Dense(32, activation='relu'))  # Segunda camada oculta\n",
    "modelo.add(Dense(1))  # Camada de saída (regressão)\n",
    "\n",
    "# Compilar o modelo\n",
    "modelo.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "modelo.fit(X_treino, y_treino, epochs=50, batch_size=32, verbose=1, validation_split=0.2)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_teste = modelo.predict(X_teste).flatten()  # Flatten para transformar em 1D\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Mean Squared Error (MSE) no teste:\", mse)\n",
    "print(\"R² score no teste:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "dataset_teste.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) no teste: 0.22907692307692307\n",
      "R² score no teste: 0.032150000000000234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/1732875705.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>stocks</th>\n",
       "      <th>playoff_previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.494162</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631008</td>\n",
       "      <td>0.613080</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.427084</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IND</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478243</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.557230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MIN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.499098</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NYL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516902</td>\n",
       "      <td>0.679304</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SAC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488918</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.359621</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SEA</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto\n",
       "1    ATL    10      1.0  0.569981  0.695814  0.545741              0.91\n",
       "11   CHI    10      0.0  0.434645  0.494162  0.630915              0.69\n",
       "21   CON    10      0.0  0.631008  0.613080  0.315457              0.22\n",
       "30   DET    10      1.0  0.667559  0.427084  0.268139              0.86\n",
       "47   IND    10      1.0  0.478243  0.561043  0.659306              0.45\n",
       "56   LAS    10      1.0  0.791341  0.557230  1.000000              0.94\n",
       "67   MIN    10      0.0  0.684573  0.499098  0.772871              0.89\n",
       "76   NYL    10      0.0  0.516902  0.679304  0.362776              0.77\n",
       "87   PHO    10      1.0  0.717072  0.688872  0.476341              0.86\n",
       "98   SAC    10      0.0  0.488918  0.617841  0.359621              0.45\n",
       "105  SAS    10      1.0  0.381001  0.680233  0.511041              0.81\n",
       "114  SEA    10      1.0  0.391775  0.553947  0.394322              0.57\n",
       "125  WAS    10      1.0  0.431818  0.681163  0.271293              0.46"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar o modelo de regressão com Extra Trees\n",
    "modelo = ExtraTreesRegressor(random_state=42)\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Mean Squared Error (MSE) no teste:\", mse)\n",
    "print(\"R² score no teste:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "dataset_teste.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) no teste: 0.23758751658811145\n",
      "R² score no teste: -0.00380725758477074\n",
      "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto\n",
      "1    ATL    10      1.0  0.569981  0.695814  0.545741          0.585366\n",
      "11   CHI    10      0.0  0.434645  0.494162  0.630915          0.585366\n",
      "21   CON    10      0.0  0.631008  0.613080  0.315457          0.585366\n",
      "30   DET    10      1.0  0.667559  0.427084  0.268139          0.585366\n",
      "47   IND    10      1.0  0.478243  0.561043  0.659306          0.585366\n",
      "56   LAS    10      1.0  0.791341  0.557230  1.000000          0.585366\n",
      "67   MIN    10      0.0  0.684573  0.499098  0.772871          0.585366\n",
      "76   NYL    10      0.0  0.516902  0.679304  0.362776          0.585366\n",
      "87   PHO    10      1.0  0.717072  0.688872  0.476341          0.585366\n",
      "98   SAC    10      0.0  0.488918  0.617841  0.359621          0.585366\n",
      "105  SAS    10      1.0  0.381001  0.680233  0.511041          0.585366\n",
      "114  SEA    10      1.0  0.391775  0.553947  0.394322          0.585366\n",
      "125  WAS    10      1.0  0.431818  0.681163  0.271293          0.585366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/3962555249.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n"
     ]
    }
   ],
   "source": [
    "# Inicializar o modelo ElasticNet\n",
    "modelo = ElasticNet(random_state=42)\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Mean Squared Error (MSE) no teste:\", mse)\n",
    "print(\"R² score no teste:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "print(dataset_teste.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) no teste: 0.17809230151985936\n",
      "R² score no teste: 0.2475600260785944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/1187298798.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>stocks</th>\n",
       "      <th>playoff_previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>1.003988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.494162</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.549502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631008</td>\n",
       "      <td>0.613080</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.218301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.427084</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.832316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IND</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478243</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.557558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.557230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MIN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.499098</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.793431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NYL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516902</td>\n",
       "      <td>0.679304</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.416923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.985964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SAC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488918</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.359621</td>\n",
       "      <td>0.277197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.540825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SEA</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.456628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.404335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto\n",
       "1    ATL    10      1.0  0.569981  0.695814  0.545741          1.003988\n",
       "11   CHI    10      0.0  0.434645  0.494162  0.630915          0.549502\n",
       "21   CON    10      0.0  0.631008  0.613080  0.315457          0.218301\n",
       "30   DET    10      1.0  0.667559  0.427084  0.268139          0.832316\n",
       "47   IND    10      1.0  0.478243  0.561043  0.659306          0.557558\n",
       "56   LAS    10      1.0  0.791341  0.557230  1.000000          0.980005\n",
       "67   MIN    10      0.0  0.684573  0.499098  0.772871          0.793431\n",
       "76   NYL    10      0.0  0.516902  0.679304  0.362776          0.416923\n",
       "87   PHO    10      1.0  0.717072  0.688872  0.476341          0.985964\n",
       "98   SAC    10      0.0  0.488918  0.617841  0.359621          0.277197\n",
       "105  SAS    10      1.0  0.381001  0.680233  0.511041          0.540825\n",
       "114  SEA    10      1.0  0.391775  0.553947  0.394322          0.456628\n",
       "125  WAS    10      1.0  0.431818  0.681163  0.271293          0.404335"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar o modelo XGBoost Regressor\n",
    "modelo = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Mean Squared Error (MSE) no teste:\", mse)\n",
    "print(\"R² score no teste:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "dataset_teste.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15\n",
      "[LightGBM] [Info] Number of data points in the train set: 41, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 0.585366\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Mean Squared Error (MSE) no teste: 0.22311644574616202\n",
      "R² score no teste: 0.0573330167224656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/3421237157.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>stocks</th>\n",
       "      <th>playoff_previsto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>0.649998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.494162</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.523811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631008</td>\n",
       "      <td>0.613080</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.649998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.427084</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>0.523811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IND</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478243</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.649998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.557230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MIN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.499098</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.523811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NYL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516902</td>\n",
       "      <td>0.679304</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.649998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.649998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SAC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488918</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.359621</td>\n",
       "      <td>0.649998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.649998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SEA</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.649998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.649998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto\n",
       "1    ATL    10      1.0  0.569981  0.695814  0.545741          0.649998\n",
       "11   CHI    10      0.0  0.434645  0.494162  0.630915          0.523811\n",
       "21   CON    10      0.0  0.631008  0.613080  0.315457          0.649998\n",
       "30   DET    10      1.0  0.667559  0.427084  0.268139          0.523811\n",
       "47   IND    10      1.0  0.478243  0.561043  0.659306          0.649998\n",
       "56   LAS    10      1.0  0.791341  0.557230  1.000000          0.649998\n",
       "67   MIN    10      0.0  0.684573  0.499098  0.772871          0.523811\n",
       "76   NYL    10      0.0  0.516902  0.679304  0.362776          0.649998\n",
       "87   PHO    10      1.0  0.717072  0.688872  0.476341          0.649998\n",
       "98   SAC    10      0.0  0.488918  0.617841  0.359621          0.649998\n",
       "105  SAS    10      1.0  0.381001  0.680233  0.511041          0.649998\n",
       "114  SEA    10      1.0  0.391775  0.553947  0.394322          0.649998\n",
       "125  WAS    10      1.0  0.431818  0.681163  0.271293          0.649998"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar o modelo LightGBM Regressor\n",
    "modelo = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Mean Squared Error (MSE) no teste:\", mse)\n",
    "print(\"R² score no teste:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "dataset_teste.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) no teste: 0.16150240458566234\n",
      "R² score no teste: 0.3176523406255768\n",
      "Previsões corretas: 11 de 13 (84.62%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55727/3889390853.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['playoff_previsto'] = y_pred_teste\n",
      "/tmp/ipykernel_55727/3889390853.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_teste['correto'] = ((dataset_teste['playoff'] == 1) & (dataset_teste['playoff_previsto'] > 0.5)) | \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>playoff</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>stocks</th>\n",
       "      <th>playoff_previsto</th>\n",
       "      <th>correto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569981</td>\n",
       "      <td>0.695814</td>\n",
       "      <td>0.545741</td>\n",
       "      <td>0.968918</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434645</td>\n",
       "      <td>0.494162</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.823756</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CON</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631008</td>\n",
       "      <td>0.613080</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.292490</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DET</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.427084</td>\n",
       "      <td>0.268139</td>\n",
       "      <td>1.051501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>IND</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.478243</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>0.626726</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>LAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791341</td>\n",
       "      <td>0.557230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895035</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>MIN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684573</td>\n",
       "      <td>0.499098</td>\n",
       "      <td>0.772871</td>\n",
       "      <td>0.775672</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NYL</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516902</td>\n",
       "      <td>0.679304</td>\n",
       "      <td>0.362776</td>\n",
       "      <td>0.457772</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PHO</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717072</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.476341</td>\n",
       "      <td>0.949047</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SAC</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488918</td>\n",
       "      <td>0.617841</td>\n",
       "      <td>0.359621</td>\n",
       "      <td>0.424344</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.511041</td>\n",
       "      <td>0.716863</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SEA</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.391775</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>0.765838</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>WAS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.681163</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.770754</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tmID  year  playoff       PER      eFG%    stocks  playoff_previsto  \\\n",
       "1    ATL    10      1.0  0.569981  0.695814  0.545741          0.968918   \n",
       "11   CHI    10      0.0  0.434645  0.494162  0.630915          0.823756   \n",
       "21   CON    10      0.0  0.631008  0.613080  0.315457          0.292490   \n",
       "30   DET    10      1.0  0.667559  0.427084  0.268139          1.051501   \n",
       "47   IND    10      1.0  0.478243  0.561043  0.659306          0.626726   \n",
       "56   LAS    10      1.0  0.791341  0.557230  1.000000          0.895035   \n",
       "67   MIN    10      0.0  0.684573  0.499098  0.772871          0.775672   \n",
       "76   NYL    10      0.0  0.516902  0.679304  0.362776          0.457772   \n",
       "87   PHO    10      1.0  0.717072  0.688872  0.476341          0.949047   \n",
       "98   SAC    10      0.0  0.488918  0.617841  0.359621          0.424344   \n",
       "105  SAS    10      1.0  0.381001  0.680233  0.511041          0.716863   \n",
       "114  SEA    10      1.0  0.391775  0.553947  0.394322          0.765838   \n",
       "125  WAS    10      1.0  0.431818  0.681163  0.271293          0.770754   \n",
       "\n",
       "     correto  \n",
       "1       True  \n",
       "11     False  \n",
       "21      True  \n",
       "30      True  \n",
       "47      True  \n",
       "56      True  \n",
       "67     False  \n",
       "76      True  \n",
       "87      True  \n",
       "98      True  \n",
       "105     True  \n",
       "114     True  \n",
       "125     True  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar o modelo de regressão com Gradient Boosting\n",
    "modelo = GradientBoostingRegressor(random_state=42) #TODO porque foi o melhor modelo até agora\n",
    "\n",
    "# Treinar o modelo com os dados de treino\n",
    "modelo.fit(X_treino, y_treino)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred_teste = modelo.predict(X_teste)\n",
    "\n",
    "# Avaliar o modelo com métricas de regressão\n",
    "mse = mean_squared_error(y_teste, y_pred_teste)\n",
    "r2 = r2_score(y_teste, y_pred_teste)\n",
    "\n",
    "# Exibir as métricas\n",
    "print(\"Mean Squared Error (MSE) no teste:\", mse)\n",
    "print(\"R² score no teste:\", r2)\n",
    "\n",
    "# Adicionar a coluna prevista ao dataset_teste\n",
    "dataset_teste['playoff_previsto'] = y_pred_teste\n",
    "\n",
    "# Critério de correção\n",
    "# 1. Quando 'playoff' é 1, 'playoff_previsto' deve ser > 0.5\n",
    "# 2. Quando 'playoff' é 0, 'playoff_previsto' deve ser <= 0.5\n",
    "\n",
    "# Criar uma coluna indicando se a previsão está correta\n",
    "dataset_teste['correto'] = ((dataset_teste['playoff'] == 1) & (dataset_teste['playoff_previsto'] > 0.5)) | \\\n",
    "                           ((dataset_teste['playoff'] == 0) & (dataset_teste['playoff_previsto'] <= 0.5))\n",
    "\n",
    "# Contar o número de previsões corretas\n",
    "corretos = dataset_teste['correto'].sum()\n",
    "\n",
    "# Número total de exemplos\n",
    "total = len(dataset_teste)\n",
    "\n",
    "# Exibir o resultado\n",
    "print(f\"Previsões corretas: {corretos} de {total} ({(corretos / total) * 100:.2f}%)\")\n",
    "\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "dataset_teste.head(15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
