{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df1 = pd.read_csv('datasets/players.csv')\n",
    "df2 = pd.read_csv('datasets/players_teams.csv')\n",
    "df3 = pd.read_csv('datasets/awards_players.csv')\n",
    "df4 = pd.read_csv('datasets/teams.csv')\n",
    "df5 = pd.read_csv('datasets/teams_post.csv')\n",
    "df6 = pd.read_csv('datasets/coaches.csv')\n",
    "df7 = pd.read_csv('datasets/series_post.csv')\n",
    "\n",
    "def corrige_vencedor(teams, series_post):\n",
    "    # Itera sobre cada rodada ('F', 'CF', 'FR') para ajustar cada fase dos playoffs\n",
    "    for round_type in ['FR', 'CF', 'F']:\n",
    "        # Filtra a série específica da rodada\n",
    "        series_round = series_post[series_post['round'] == round_type]\n",
    "        \n",
    "        # Atualiza cada série individualmente\n",
    "        for _, row in series_round.iterrows():\n",
    "            year = row['year']\n",
    "            winner_id = row['tmIDWinner']\n",
    "            loser_id = row['tmIDLoser']\n",
    "            \n",
    "            # Define as colunas que correspondem às rodadas\n",
    "            if round_type == 'FR':\n",
    "                round_column = 'firstRound'\n",
    "            elif round_type == 'CF':\n",
    "                round_column = 'semis'\n",
    "            elif round_type == 'F':\n",
    "                round_column = 'finals'\n",
    "            \n",
    "            # Marca o time vencedor como \"W\" na rodada correspondente\n",
    "            teams.loc[(teams['year'] == year) & (teams['tmID'] == winner_id), round_column] = 'W'\n",
    "            \n",
    "            # Marca o time perdedor como \"L\" na rodada correspondente\n",
    "            teams.loc[(teams['year'] == year) & (teams['tmID'] == loser_id), round_column] = 'L'\n",
    "    \n",
    "    return teams\n",
    "\n",
    "teams_file = corrige_vencedor(df4, df7)\n",
    "\n",
    "players_teams_file = df2.drop(columns=['lgID'])\n",
    "players_file = df1[df1['pos'].notna() & (df1['pos'] != '')]\n",
    "players_file = players_file.drop(columns=['firstseason', 'lastseason', 'deathDate', 'collegeOther'])\n",
    "players_file['college'] = players_file['college'].apply(lambda x: 1 if pd.notnull(x) else 0)\n",
    "merged_df = pd.merge(players_teams_file, players_file, left_on='playerID', right_on='bioID', how='left')\n",
    "merged_df = merged_df.drop(columns=['bioID'])\n",
    "awards_players_file = df3.drop(columns=['lgID'])\n",
    "teams_file = df4.drop(columns=['lgID', 'divID', 'tmORB','tmDRB','tmTRB','opptmORB','opptmDRB','opptmTRB','seeded'])\n",
    "teams_file['playoff'] = teams_file['playoff'].apply(lambda x: 1 if x=='Y' else 0)\n",
    "\n",
    "team_post_file = df5.drop(columns=['lgID'])\n",
    "series_post_file = df7.drop(columns=['lgIDWinner', 'lgIDLoser'])\n",
    "coaches_file = df6.drop(columns=['lgID'])\n",
    "\n",
    "\n",
    "awards_grouped = awards_players_file.groupby(['playerID', 'year'])['award'].apply(list).reset_index()\n",
    "awards_grouped['award'] = awards_grouped['award'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "merged_df = pd.merge(merged_df, awards_grouped, on=['playerID', 'year'], how='left')\n",
    "merged_df['award'] = merged_df['award'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "merged_df = pd.merge(merged_df, teams_file, on=['tmID','year'], how = 'left')\n",
    "\n",
    "merged_df = merged_df.drop(columns=['franchID', 'name'])\n",
    "\n",
    "merged_df = pd.merge(merged_df, team_post_file, on=['tmID','year'], how = 'left')\n",
    "\n",
    "print(merged_df)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_coaches_file = df3.rename(columns={'playerID': 'coachID'})\n",
    "coach_awards = awards_coaches_file[awards_coaches_file['award'] == 'Coach of the Year']\n",
    "coach_awards_grouped = coach_awards.groupby(['coachID', 'year'])['award'].apply(list).reset_index()\n",
    "coaches_file = pd.merge(coaches_file, coach_awards_grouped, on=['coachID', 'year'], how='left')\n",
    "\n",
    "print(coaches_file)\n",
    "coaches_file.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_oRebounds_by_pos = merged_df.groupby('pos')['oRebounds'].mean().reset_index()\n",
    "avg_dRebounds_by_pos = merged_df.groupby('pos')['dRebounds'].mean().reset_index()\n",
    "\n",
    "print('--------------------')\n",
    "print(avg_oRebounds_by_pos)\n",
    "print('--------------------')\n",
    "print(avg_dRebounds_by_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(columns=['rebounds', 'PostRebounds'])\n",
    "merged_df = merged_df.rename(columns={'GP_x': 'GP_player', 'GP_y': 'GP_team'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = merged_df.groupby('year').agg({\n",
    "    'o_pts': 'sum',\n",
    "    'o_fga': 'sum',\n",
    "    'o_oreb': 'sum',\n",
    "    'o_to': 'sum',\n",
    "    'o_fta': 'sum',\n",
    "    'o_asts': 'sum',\n",
    "    'o_fgm' : 'sum',\n",
    "    'o_ftm': 'sum',\n",
    "    'o_dreb':'sum',\n",
    "}).reset_index()\n",
    "\n",
    "grouped['VOP'] = grouped['o_pts'] / (grouped['o_fga'] - grouped['o_oreb'] + grouped['o_to'] + 0.44 * grouped['o_fta'])\n",
    "grouped['factor'] = (2 / 3) - (0.5 * (grouped['o_asts'] / grouped['o_fgm'])) / (2 * (grouped['o_fgm'] / grouped['o_ftm']))\n",
    "grouped['DRB%'] = (grouped['o_dreb'] - grouped['o_oreb']) / grouped['o_dreb']\n",
    "\n",
    "uPER_df = merged_df.groupby(['playerID', 'year']).agg({\n",
    "    'minutes': 'sum',     \n",
    "    'threeMade': 'sum',   \n",
    "    'assists': 'sum',     \n",
    "    'fgMade': 'sum',      \n",
    "    'ftMade': 'sum',      \n",
    "    'turnovers': 'sum',   \n",
    "    'fgAttempted': 'sum', \n",
    "    'ftAttempted': 'sum', \n",
    "    'dRebounds': 'sum',   \n",
    "    'oRebounds': 'sum',   \n",
    "    'steals': 'sum',      \n",
    "    'blocks': 'sum',      \n",
    "    'PF': 'sum'           \n",
    "}).reset_index()\n",
    "\n",
    "uPER_df = uPER_df.merge(grouped[['year', 'VOP', 'factor', 'DRB%']], on='year')\n",
    "\n",
    "uPER_df['TRB'] = uPER_df['dRebounds'] + uPER_df['oRebounds']\n",
    "\n",
    "uPER_df['uPER'] = (1 / uPER_df['minutes']) * (\n",
    "    uPER_df['threeMade'] +\n",
    "    (2/3) * uPER_df['assists'] +\n",
    "    (2 - uPER_df['factor'] * (uPER_df['assists'] / uPER_df['fgMade'])) * uPER_df['fgMade'] +\n",
    "    (uPER_df['ftMade'] * 0.5 * (1 + (1 - (uPER_df['assists'] / uPER_df['fgMade'])) + (2/3) * (uPER_df['assists'] / uPER_df['fgMade']))) -\n",
    "    uPER_df['VOP'] * uPER_df['turnovers'] -\n",
    "    uPER_df['VOP'] * uPER_df['DRB%'] * (uPER_df['fgAttempted'] - uPER_df['fgMade']) -\n",
    "    uPER_df['VOP'] * 0.44 * (0.44 + (0.56 * uPER_df['DRB%'])) * (uPER_df['ftAttempted'] - uPER_df['ftMade']) +\n",
    "    uPER_df['VOP'] * (1 - uPER_df['DRB%']) * uPER_df['TRB'] +\n",
    "    uPER_df['VOP'] * uPER_df['DRB%'] * uPER_df['oRebounds'] +\n",
    "    uPER_df['VOP'] * uPER_df['steals'] +\n",
    "    uPER_df['VOP'] * uPER_df['DRB%'] * uPER_df['blocks'] -\n",
    "    uPER_df['PF'] * ((grouped['o_ftm'].mean() / grouped['o_pts'].mean()) - 0.44 * (grouped['o_fta'].mean() / grouped['o_pts'].mean()) * uPER_df['VOP'])\n",
    ")\n",
    "\n",
    "lg_uPER = uPER_df.groupby('year')['uPER'].mean().reset_index()\n",
    "lg_uPER.rename(columns={'uPER': 'lg_uPER'}, inplace=True)\n",
    "\n",
    "uPER_df = uPER_df.merge(lg_uPER, on='year')\n",
    "\n",
    "uPER_df['PER'] = uPER_df['uPER'] * (15 / uPER_df['lg_uPER'])\n",
    "\n",
    "print(uPER_df[['playerID', 'year', 'uPER', 'PER']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_to_merge = uPER_df[['playerID', 'year', 'PER']]\n",
    "merged_df = merged_df.merge(per_to_merge, on=['playerID', 'year'], how='left')\n",
    "\n",
    "merged_df['TS%'] = (merged_df['points'] / (2 * (merged_df['fgAttempted'] + 0.44 * merged_df['ftAttempted'])))*100\n",
    "merged_df['eFG%'] = ((merged_df['fgMade'] + 0.5 * merged_df['threeMade']) / merged_df['fgAttempted'])*100\n",
    "\n",
    "merged_df['PER'] = merged_df['PER'].fillna(0)\n",
    "merged_df['TS%'] = merged_df['TS%'].fillna(0)\n",
    "merged_df['eFG%'] = merged_df['eFG%'].fillna(0)\n",
    "\n",
    "#Equipas que não foram aos playoffs\n",
    "merged_df['W'] = merged_df['W'].fillna(0)\n",
    "merged_df['L'] = merged_df['L'].fillna(0)\n",
    "\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot_for_each_column(dataset):\n",
    "    numeric_columns = dataset.select_dtypes(include='number')\n",
    "    if numeric_columns.empty:\n",
    "        print(\"No numeric columns found in the dataset.\")\n",
    "    else:\n",
    "        numeric_columns.boxplot(figsize=(10, 6))\n",
    "        plt.title(\"Boxplot for all numeric columns\")\n",
    "        plt.xticks(rotation=45)  # Rotation in x, if necessary\n",
    "        plt.show()\n",
    "\n",
    "def pearson_correlation(dataset, size_x, size_y):\n",
    "    numeric_columns = dataset.select_dtypes(include='number')\n",
    "    \n",
    "    if numeric_columns.empty:\n",
    "        print(\"Nenhuma coluna numérica encontrada no dataset.\")\n",
    "    else:\n",
    "        # Correlation matrix\n",
    "        correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "        # View\n",
    "        plt.figure(figsize=(size_x, size_y))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        plt.title('Pearson-correlation')\n",
    "        plt.show()\n",
    "\n",
    "def bar_chart_for_each_column(dataset):\n",
    "    non_numeric_columns = dataset.select_dtypes(exclude='number')\n",
    "    if non_numeric_columns.empty:\n",
    "        print(\"Any non-numeric columns found in the dataset.\")\n",
    "    else:\n",
    "        for column in non_numeric_columns.columns:\n",
    "            value_counts = non_numeric_columns[column].value_counts()\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            value_counts.plot(kind='bar')\n",
    "            plt.title(f\"Bar chart for '{column}'\")\n",
    "            plt.xlabel(column)\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "            plt.show()\n",
    "\n",
    "# Pie-chart for each column\n",
    "def pie_chart_for_each_column(dataset):\n",
    "    non_numeric_columns = dataset.select_dtypes(exclude='number')\n",
    "    \n",
    "    if non_numeric_columns.empty:\n",
    "        print(\"Any non-numeric columns found in the dataset.\")\n",
    "    else:\n",
    "        for column in non_numeric_columns.columns:\n",
    "            # Count elements from different categories\n",
    "            category_counts = dataset[column].value_counts()\n",
    "            \n",
    "            # Pie-chart\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            category_counts.plot.pie(autopct='%1.1f%%', startangle=140)\n",
    "            plt.title(f'Distribution of {column}')\n",
    "            plt.ylabel('')  # Remove o rótulo do eixo Y\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "#box_plot_for_each_column(merged_df)\n",
    "#box_plot_for_each_column(coaches_file)\n",
    "#box_plot_for_each_column(series_post_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearson_correlation(merged_df, 100, 80)\n",
    "#pearson_correlation(coaches_file, 8, 6)\n",
    "#pearson_correlation(series_post_file, 8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar_chart_for_each_column(merged_df)\n",
    "#bar_chart_for_each_column(coaches_file)\n",
    "#bar_chart_for_each_column(series_post_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pie_chart_for_each_column(merged_df)\n",
    "#pie_chart_for_each_column(coaches_file)\n",
    "#pie_chart_for_each_column(series_post_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceGameResults(column):\n",
    "    return column.apply(lambda value: '100' if value == 'W' else '010' if value == 'L' else '001')\n",
    "\n",
    "# Aplicar a função para cada coluna específica\n",
    "merged_df['firstRound'] = replaceGameResults(merged_df['firstRound'])\n",
    "merged_df['semis'] = replaceGameResults(merged_df['semis'])\n",
    "merged_df['finals'] = replaceGameResults(merged_df['finals'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('cleanDatasets'):\n",
    "    os.makedirs('cleanDatasets')\n",
    "\n",
    "merged_df.to_csv('cleanDatasets/players_and_teams.csv', index=False)\n",
    "coaches_file.to_csv('cleanDatasets/coaches_and_awards.csv', index=False)\n",
    "series_post_file.to_csv('cleanDatasets/series_post.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df2 = merged_df.drop(columns=['minutes','points','threeMade','assists','fgMade','turnovers','fgAttempted','ftAttempted','dRebounds','oRebounds','steals','blocks','PF','o_ftm','o_pts','o_fta','o_pts','o_fga','o_oreb','o_to','o_asts','o_fgm','o_dreb'])\n",
    "merged_df2 = merged_df2.drop(columns=['GP_player','GS','ftMade','threeAttempted','GP_team'])\n",
    "merged_df2 = merged_df2.drop(columns=['o_3pm','o_3pa','o_reb','o_pf','o_stl','o_blk','d_fgm','d_fga','d_ftm','d_fta','d_3pm','d_3pa','d_oreb','d_dreb','d_reb','d_asts','d_pf','d_stl','d_to','d_blk','d_pts'])\n",
    "merged_df2 = merged_df2.drop(columns=['PostGP','PostGS','PostMinutes','PostPoints','PostoRebounds','PostdRebounds','PostAssists','PostSteals','PostBlocks','PostTurnovers','PostPF','PostfgAttempted','PostfgMade','PostftAttempted','PostftMade','PostthreeAttempted','PostthreeMade','PostDQ'])\n",
    "merged_df2 = merged_df2.drop(columns=['arena'])\n",
    "\n",
    "merged_df2['birthDate'] = pd.to_datetime(merged_df['birthDate'], errors='coerce').dt.year\n",
    "merged_df2 = merged_df2.rename(columns={'birthDate': 'birthYear'})\n",
    "\n",
    "if not os.path.exists('cleanDatasets'):\n",
    "    os.makedirs('cleanDatasets')\n",
    "\n",
    "merged_df2.to_csv('cleanDatasets/advancedstatistics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerID</th>\n",
       "      <th>year</th>\n",
       "      <th>PER</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>TS%</th>\n",
       "      <th>tmID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>3</td>\n",
       "      <td>19.293262</td>\n",
       "      <td>42.150171</td>\n",
       "      <td>48.849265</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>4</td>\n",
       "      <td>15.898093</td>\n",
       "      <td>40.822785</td>\n",
       "      <td>42.774629</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>5</td>\n",
       "      <td>18.485960</td>\n",
       "      <td>43.684211</td>\n",
       "      <td>48.457881</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>6</td>\n",
       "      <td>14.545585</td>\n",
       "      <td>42.446043</td>\n",
       "      <td>45.842753</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>7</td>\n",
       "      <td>18.086335</td>\n",
       "      <td>45.471014</td>\n",
       "      <td>49.331429</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>8</td>\n",
       "      <td>15.269770</td>\n",
       "      <td>46.058091</td>\n",
       "      <td>49.015953</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>9</td>\n",
       "      <td>20.282752</td>\n",
       "      <td>51.845638</td>\n",
       "      <td>54.430140</td>\n",
       "      <td>CON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abrossv01w</td>\n",
       "      <td>10</td>\n",
       "      <td>11.964576</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>41.182171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adamsjo01w</td>\n",
       "      <td>5</td>\n",
       "      <td>18.415523</td>\n",
       "      <td>46.969697</td>\n",
       "      <td>48.701299</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aguilel01w</td>\n",
       "      <td>4</td>\n",
       "      <td>11.934379</td>\n",
       "      <td>59.090909</td>\n",
       "      <td>59.589800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ajavoma01w</td>\n",
       "      <td>10</td>\n",
       "      <td>15.008524</td>\n",
       "      <td>35.387324</td>\n",
       "      <td>42.124429</td>\n",
       "      <td>WAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ajavoma01w</td>\n",
       "      <td>11</td>\n",
       "      <td>15.119377</td>\n",
       "      <td>39.130435</td>\n",
       "      <td>45.122760</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aldrima01w</td>\n",
       "      <td>2</td>\n",
       "      <td>8.622283</td>\n",
       "      <td>51.851852</td>\n",
       "      <td>49.466080</td>\n",
       "      <td>WAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>aldrima01w</td>\n",
       "      <td>3</td>\n",
       "      <td>2.867189</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>37.076271</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>alhalta01w</td>\n",
       "      <td>3</td>\n",
       "      <td>7.519200</td>\n",
       "      <td>36.206897</td>\n",
       "      <td>38.185786</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      playerID  year        PER       eFG%        TS% tmID\n",
       "0   abrossv01w     3  19.293262  42.150171  48.849265  MIN\n",
       "1   abrossv01w     4  15.898093  40.822785  42.774629  MIN\n",
       "2   abrossv01w     5  18.485960  43.684211  48.457881  MIN\n",
       "3   abrossv01w     6  14.545585  42.446043  45.842753  MIN\n",
       "4   abrossv01w     7  18.086335  45.471014  49.331429  MIN\n",
       "5   abrossv01w     8  15.269770  46.058091  49.015953  MIN\n",
       "6   abrossv01w     9  20.282752  51.845638  54.430140  CON\n",
       "7   abrossv01w    10  11.964576  33.333333  41.182171  NaN\n",
       "8   adamsjo01w     5  18.415523  46.969697  48.701299  NaN\n",
       "9   aguilel01w     4  11.934379  59.090909  59.589800  NaN\n",
       "10  ajavoma01w    10  15.008524  35.387324  42.124429  WAS\n",
       "11  ajavoma01w    11  15.119377  39.130435  45.122760  NaN\n",
       "12  aldrima01w     2   8.622283  51.851852  49.466080  WAS\n",
       "13  aldrima01w     3   2.867189  33.333333  37.076271  NaN\n",
       "14  alhalta01w     3   7.519200  36.206897  38.185786  NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_stats_prevYear = merged_df2[['playerID','year','PER', 'eFG%', 'TS%']].drop_duplicates().copy()\n",
    "players_stats_prevYear['year'] = players_stats_prevYear['year'] + 1\n",
    "players_stats_prevYear = players_stats_prevYear.merge(\n",
    "    merged_df2[['playerID', 'year', 'tmID']], \n",
    "    on=['playerID', 'year'], \n",
    "    how='left')\n",
    "\n",
    "players_stats_prevYear.to_csv('cleanDatasets/players_stats_prevYear.csv', index=False)\n",
    "\n",
    "players_stats_prevYear.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmID</th>\n",
       "      <th>year</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>eFG%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>9</td>\n",
       "      <td>14.855192</td>\n",
       "      <td>48.797175</td>\n",
       "      <td>45.746779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>10</td>\n",
       "      <td>17.505053</td>\n",
       "      <td>49.771367</td>\n",
       "      <td>45.945109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHA</td>\n",
       "      <td>2</td>\n",
       "      <td>16.236160</td>\n",
       "      <td>51.201663</td>\n",
       "      <td>45.908824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHA</td>\n",
       "      <td>3</td>\n",
       "      <td>13.585956</td>\n",
       "      <td>47.676058</td>\n",
       "      <td>40.657804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHA</td>\n",
       "      <td>4</td>\n",
       "      <td>16.781000</td>\n",
       "      <td>51.888158</td>\n",
       "      <td>46.154392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHA</td>\n",
       "      <td>5</td>\n",
       "      <td>15.772778</td>\n",
       "      <td>49.524802</td>\n",
       "      <td>45.034801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CHA</td>\n",
       "      <td>6</td>\n",
       "      <td>14.139178</td>\n",
       "      <td>45.994844</td>\n",
       "      <td>40.331706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHA</td>\n",
       "      <td>7</td>\n",
       "      <td>14.729580</td>\n",
       "      <td>46.097397</td>\n",
       "      <td>40.573712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHI</td>\n",
       "      <td>7</td>\n",
       "      <td>13.484013</td>\n",
       "      <td>47.462532</td>\n",
       "      <td>44.335021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHI</td>\n",
       "      <td>8</td>\n",
       "      <td>13.057702</td>\n",
       "      <td>45.508210</td>\n",
       "      <td>40.083930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CHI</td>\n",
       "      <td>9</td>\n",
       "      <td>16.124573</td>\n",
       "      <td>45.521739</td>\n",
       "      <td>40.602352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CHI</td>\n",
       "      <td>10</td>\n",
       "      <td>14.516353</td>\n",
       "      <td>48.523196</td>\n",
       "      <td>44.406606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CLE</td>\n",
       "      <td>2</td>\n",
       "      <td>16.011102</td>\n",
       "      <td>53.069038</td>\n",
       "      <td>49.040955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CLE</td>\n",
       "      <td>3</td>\n",
       "      <td>17.349000</td>\n",
       "      <td>49.408451</td>\n",
       "      <td>46.367474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CLE</td>\n",
       "      <td>4</td>\n",
       "      <td>17.364208</td>\n",
       "      <td>47.750343</td>\n",
       "      <td>43.514878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tmID  year        PER        TS%       eFG%\n",
       "0   ATL     9  14.855192  48.797175  45.746779\n",
       "1   ATL    10  17.505053  49.771367  45.945109\n",
       "2   CHA     2  16.236160  51.201663  45.908824\n",
       "3   CHA     3  13.585956  47.676058  40.657804\n",
       "4   CHA     4  16.781000  51.888158  46.154392\n",
       "5   CHA     5  15.772778  49.524802  45.034801\n",
       "6   CHA     6  14.139178  45.994844  40.331706\n",
       "7   CHA     7  14.729580  46.097397  40.573712\n",
       "8   CHI     7  13.484013  47.462532  44.335021\n",
       "9   CHI     8  13.057702  45.508210  40.083930\n",
       "10  CHI     9  16.124573  45.521739  40.602352\n",
       "11  CHI    10  14.516353  48.523196  44.406606\n",
       "12  CLE     2  16.011102  53.069038  49.040955\n",
       "13  CLE     3  17.349000  49.408451  46.367474\n",
       "14  CLE     4  17.364208  47.750343  43.514878"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula a média de PER, TS%, e eFG% por equipe e ano\n",
    "team_year_stats = players_stats_prevYear.groupby(['tmID', 'year'])[['PER', 'TS%', 'eFG%']].mean().reset_index()\n",
    "\n",
    "# Salva o novo dataset em um arquivo CSV\n",
    "team_year_stats.to_csv('cleanDatasets/team_year_stats.csv', index=False)\n",
    "\n",
    "# Visualizar os primeiros dados para verificar o resultado\n",
    "team_year_stats.head(15)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
